{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b8e4f02-a30d-49cc-9706-d2d4ca774d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f3bd6c-fac4-4c7f-a2c6-0d2539b1eb88",
   "metadata": {},
   "source": [
    "## Load and Normalize Data\n",
    "To compute the spectral efficiency, both transmitter and receiver should be optimized with NN. So the dataset contains F_opt and W_opt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ccf77fc-a95d-4b0d-adc6-b84ddfe4be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_layouts = 10000\n",
    "test_layouts = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "103c8548-2cbc-4b72-be94-7bdd1f281584",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('hb_train_144_36.mat')\n",
    "Fopt_train = data['Fopt'].transpose(2,0,1)\n",
    "Wopt_train = data['Wopt'].transpose(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64534188-f9a7-43e0-b974-b483feabf046",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = scipy.io.loadmat('hb_test_144_36.mat')\n",
    "Fopt_test = test_data['Fopt'].transpose(2,0,1)\n",
    "Wopt_test = test_data['Wopt'].transpose(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ca9612d-c75f-4e70-b1bd-68461ef211e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(train_data,test_data):\n",
    "    n1, n2 = train_data.shape[0], test_data.shape[0]\n",
    "    norm_train = train_data.reshape(n1,-1)\n",
    "    norm_test = test_data.reshape(n2,-1)\n",
    "    \n",
    "    norm_train = np.concatenate((norm_train.real, norm_train.imag),axis = 1)\n",
    "    norm_test = np.concatenate((norm_test.real, norm_test.imag),axis = 1)\n",
    "    return norm_train, norm_test\n",
    "norm_train_F, norm_test_F = normalize_data(Fopt_train, Fopt_test)\n",
    "norm_train_W, norm_test_W = normalize_data(Wopt_train, Wopt_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183a8f60-918b-4bb6-b15e-e9873596a9fb",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d6312d9-a61f-43ac-93dc-f81fb4099d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_F, F_opt, data_W, W_opt):\n",
    "        'Initialization'\n",
    "        self.Fdata = torch.tensor(data_F, dtype = torch.float)\n",
    "        self.F_opt = torch.tensor(F_opt, dtype = torch.cfloat)\n",
    "        self.Wdata = torch.tensor(data_W, dtype = torch.float)\n",
    "        self.W_opt = torch.tensor(W_opt, dtype = torch.cfloat)\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.Fdata)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        F = self.Fdata[index]\n",
    "        F_opt = self.F_opt[index]\n",
    "        W = self.Wdata[index]\n",
    "        W_opt = self.W_opt[index]\n",
    "        return F, F_opt, W, W_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2605c37-4968-4c64-a713-96c6fccf73f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = PCDataset(norm_train_F, Fopt_train, norm_train_W, Wopt_train)\n",
    "test_data = PCDataset(norm_test_F, Fopt_test, norm_test_W, Wopt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78a9be2e-f2c9-4820-b115-dd15d029b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, test_layouts, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc57b2-de37-46a2-a843-9a99c4ede4c0",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da5aa95-2601-4a46-9861-8349a590a38d",
   "metadata": {},
   "source": [
    "#### Loss function\n",
    "As the phase shifter matrix is block diagonal, we first define a block diagonal mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a4ac340-049f-416d-8048-be0d921a350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_r, N_t, N_RF, N_s = Wopt_train.shape[1], Fopt_train.shape[1], 18, Fopt_train.shape[2]\n",
    "Fmask = np.zeros((1,N_t, N_RF) )\n",
    "Wmask = np.zeros((1,N_r, N_RF) )\n",
    "for i in range(N_RF):\n",
    "    Fmask[0,i*N_t//N_RF: (i+1)*N_t//N_RF,i] = np.ones((N_t//N_RF) )\n",
    "    Wmask[0,i*N_r//N_RF: (i+1)*N_r//N_RF,i] = np.ones((N_r//N_RF) )\n",
    "Fmask = torch.tensor(Fmask, dtype = torch.cfloat)\n",
    "Wmask = torch.tensor(Wmask, dtype = torch.cfloat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ffe1ab-4c35-4cc4-9682-516e3de07865",
   "metadata": {},
   "source": [
    "The neural network module only needs to output F_BB and W_BB. F_RF and W_RF can be obtained by using (33) in [1].\n",
    "\n",
    "Note: New version pytorch supports complex valued auto differentiation. Please refer to https://pytorch.org/docs/stable/complex_numbers.html for details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b29d6ea-ec04-449a-9fd8-99f7bb66ddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FMF_loss(F_BB, F_opt):\n",
    "    # Compute F_RF from F_BB\n",
    "    F_BB = F_BB/torch.norm(F_BB, p = 'fro', dim = [1,2], keepdim = True) * math.sqrt(N_RF * N_s)\n",
    "    F_RF = F_opt @ F_BB.conj().transpose(1,2)\n",
    "    F_RF = F_RF/torch.abs(F_RF)\n",
    "    F_RF = Fmask * F_RF / math.sqrt(N_t)\n",
    "    # Matrix factorization loss\n",
    "    return torch.mean(torch.norm(F_opt - F_RF @ F_BB, dim = [1,2])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46b28283-7812-412a-a628-6df078654276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WMF_loss(W_BB, W_opt):\n",
    "    # Compute W_RF from W_BB\n",
    "    W_BB = W_BB/torch.norm(W_BB, p = 'fro', dim = [1,2], keepdim = True) * math.sqrt(N_RF * N_s)\n",
    "    W_RF = W_opt @ W_BB.conj().transpose(1,2)\n",
    "    W_RF = W_RF/torch.abs(W_RF)\n",
    "    W_RF = Wmask * W_RF / math.sqrt(N_r)\n",
    "    # Matrix factorization loss\n",
    "    return torch.mean(torch.norm(W_opt - W_RF @ W_BB, dim = [1,2])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f279c39b-89f2-442f-b147-8b9187e18527",
   "metadata": {},
   "source": [
    "#### Standard MLP modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6098ef1-8668-4fbe-be5b-8af134138198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU, Sigmoid, BatchNorm1d as BN, ReLU6 as ReLU6\n",
    "def MLP(channels, batch_norm=True):\n",
    "    return Seq(*[\n",
    "        Seq(Lin(channels[i - 1], channels[i]), ReLU(), BN(channels[i]))\n",
    "        for i in range(1, len(channels))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "063ebad9-aefb-4245-b6c3-59f57e9f8618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FNet maps F_opt to F_BB\n",
    "class FNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FNet, self).__init__()\n",
    "        self.out_dim = N_RF*N_s\n",
    "        self.mlp = MLP([N_t * N_s * 2, 100, 100])\n",
    "        self.mlp = Seq(*[self.mlp,Seq(Lin(100, 2*N_RF*N_s))])\n",
    "\n",
    "    def forward(self, data):\n",
    "        bs = data.shape[0]\n",
    "        out = self.mlp(data)\n",
    "        out_real = torch.unsqueeze(out[:, :self.out_dim], axis = -1)\n",
    "        out_imag = torch.unsqueeze(out[:, self.out_dim:self.out_dim*2], axis = -1)\n",
    "        out = torch.cat((out_real, out_imag), axis = -1)\n",
    "        out = torch.view_as_complex(out)\n",
    "        return out.reshape((bs,N_RF,N_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b54ce6dc-75cb-4481-98fb-8d7f055f07ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WNet maps W_opt to W_BB\n",
    "class WNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WNet, self).__init__()\n",
    "        self.out_dim = N_RF*N_s\n",
    "        self.mlp = MLP([N_r * N_s * 2, 100, 100])\n",
    "        self.mlp = Seq(*[self.mlp,Seq(Lin(100, 2*N_RF*N_s))])\n",
    "\n",
    "    def forward(self, data):\n",
    "        bs = data.shape[0]\n",
    "        out = self.mlp(data)\n",
    "        out_real = torch.unsqueeze(out[:, :self.out_dim], axis = -1)\n",
    "        out_imag = torch.unsqueeze(out[:, self.out_dim:self.out_dim*2], axis = -1)\n",
    "        out = torch.cat((out_real, out_imag), axis = -1)\n",
    "        out = torch.view_as_complex(out)\n",
    "        return out.reshape((bs,N_RF,N_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447f2c6a-da0f-4aa4-8b84-5f8020b0f49d",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0728facc-54e9-4609-b4b0-e25875b67d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    \"\"\" Train for one epoch. \"\"\"\n",
    "    Fmodel.train()\n",
    "    Wmodel.train()\n",
    "    loss_all = 0\n",
    "    for batch_idx, (F_train, F_opt_train, W_train, W_opt_train) in enumerate(train_loader):\n",
    "        #data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        Foutput = Fmodel(F_train)\n",
    "        Woutput = Wmodel(W_train)\n",
    "        loss = FMF_loss(Foutput, F_opt_train) + WMF_loss(Woutput, W_opt_train)\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * len(F_train)\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0befb817-4fd1-4baf-8b76-07b819c1499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader):\n",
    "    Fmodel.eval()\n",
    "    Wmodel.eval()\n",
    "    correct = 0\n",
    "    for (F_test, F_opt_test, W_test, W_opt_test) in loader:\n",
    "        #data = data.to(device)\n",
    "        Foutput = Fmodel(F_test)\n",
    "        Woutput = Wmodel(W_test)\n",
    "        loss = FMF_loss(Foutput, F_opt_test) + WMF_loss(Woutput, W_opt_test)\n",
    "        correct += loss.item() * len(F_test)\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf3d3bbd-17d3-4946-8154-bedb9005c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fmodel = FNet()\n",
    "Wmodel = WNet()\n",
    "optimizer = torch.optim.Adam(list(Fmodel.parameters()) + list(Wmodel.parameters()), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16b4fb59-fecb-45f2-9c5c-896d6bfcda2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000, Train Rate: 3.0085, Test Rate: 3.0117\n",
      "Epoch 010, Train Rate: 1.6671, Test Rate: 1.8445\n",
      "Epoch 020, Train Rate: 1.6114, Test Rate: 1.8241\n",
      "Epoch 030, Train Rate: 1.5894, Test Rate: 1.8211\n",
      "Epoch 040, Train Rate: 1.5748, Test Rate: 1.8191\n",
      "Epoch 050, Train Rate: 1.5662, Test Rate: 1.8200\n",
      "Epoch 060, Train Rate: 1.5588, Test Rate: 1.8196\n",
      "Epoch 070, Train Rate: 1.5531, Test Rate: 1.8195\n",
      "Epoch 080, Train Rate: 1.5493, Test Rate: 1.8210\n",
      "Epoch 090, Train Rate: 1.5451, Test Rate: 1.8217\n",
      "Epoch 100, Train Rate: 1.5420, Test Rate: 1.8210\n",
      "Epoch 110, Train Rate: 1.5410, Test Rate: 1.8230\n",
      "Epoch 120, Train Rate: 1.5372, Test Rate: 1.8216\n",
      "Epoch 130, Train Rate: 1.5358, Test Rate: 1.8244\n",
      "Epoch 140, Train Rate: 1.5334, Test Rate: 1.8242\n",
      "Epoch 150, Train Rate: 1.5318, Test Rate: 1.8217\n",
      "Epoch 160, Train Rate: 1.5315, Test Rate: 1.8243\n",
      "Epoch 170, Train Rate: 1.5284, Test Rate: 1.8253\n",
      "Epoch 180, Train Rate: 1.5271, Test Rate: 1.8251\n",
      "Epoch 190, Train Rate: 1.5263, Test Rate: 1.8275\n"
     ]
    }
   ],
   "source": [
    "record = []\n",
    "for epoch in range(0, 200):\n",
    "    if(epoch % 10 == 0):\n",
    "        train_rate = test(train_loader)\n",
    "        test_rate = test(test_loader)\n",
    "        print('Epoch {:03d}, Train Rate: {:.4f}, Test Rate: {:.4f}'.format(\n",
    "            epoch, train_rate, test_rate))\n",
    "        record.append([train_rate, test_rate])\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166ced7f-6ba0-435e-bb8e-c2c67dc88eba",
   "metadata": {},
   "source": [
    "## Compute spectral efficiency\n",
    "The rate computation function is from [1] https://github.com/yuxianghao/Alternating-minimization-algorithms-for-hybrid-precoding-in-millimeter-wave-MIMO-systems/blob/Initial/Narrowband/SDR-AltMin/main_SNR.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fee63376-d2d6-4118-a694-d0087ed6caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FBB2FRF(F_BB, F_opt):\n",
    "    F_BB = F_BB/torch.norm(F_BB, p = 'fro', dim = [1,2], keepdim = True) * math.sqrt(N_RF * N_s)\n",
    "    F_RF = F_opt @ F_BB.conj().transpose(1,2)\n",
    "    F_RF = F_RF/torch.abs(F_RF)\n",
    "    F_RF = Fmask * F_RF / math.sqrt(N_t)\n",
    "    return F_BB, F_RF\n",
    "\n",
    "def WBB2WRF(W_BB, W_opt):\n",
    "    W_BB = W_BB/torch.norm(W_BB, p = 'fro', dim = [1,2], keepdim = True) * math.sqrt(N_RF * N_s)\n",
    "    W_RF = W_opt @ W_BB.conj().transpose(1,2)\n",
    "    W_RF = W_RF/torch.abs(W_RF)\n",
    "    W_RF = Wmask * W_RF / math.sqrt(N_r)\n",
    "    return W_BB, W_RF\n",
    "\n",
    "def compute_rate(FBB, FRF, WBB, WRF, H, SNR):\n",
    "    '''Matlab code: log2(det(eye(Ns) + SNR(s)/Ns * pinv(WRF * WBB) * H(:,:,reali) * FRF * FBB * FBB' * FRF' * H(:,:,reali)' * WRF * WBB))\n",
    "    '''\n",
    "    rate = torch.log2(torch.det(torch.eye(N_s) + SNR/N_s * torch.linalg.pinv(WRF @ WBB) @ H @ FRF @ FBB @ FBB.conj().transpose(1,2)\n",
    "                                         @ FRF.conj().transpose(1,2) @ H.conj().transpose(1,2) @ WRF @ WBB))\n",
    "    return float(torch.mean(rate).detach().numpy().real)\n",
    "\n",
    "def rate_test(loader, H):\n",
    "    Fmodel.eval()\n",
    "    Wmodel.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for (F_test, F_opt, W_test, W_opt) in loader:\n",
    "            #data = data.to(device)\n",
    "            FBB = Fmodel(F_test)\n",
    "            FBB, FRF = FBB2FRF(FBB, F_opt)\n",
    "            WBB = Wmodel(W_test)\n",
    "            WBB, WRF = WBB2WRF(WBB, W_opt)\n",
    "            \n",
    "            print('MF loss:', WMF_loss(WBB, W_opt) + FMF_loss(FBB, F_opt))\n",
    "\n",
    "        SNR_dBs = np.arange(-15, 15, 5)\n",
    "        res_mlp = []\n",
    "        res_opt = []\n",
    "        res_ran = []\n",
    "        for SNR_dB in SNR_dBs:\n",
    "            SNR = 10**(SNR_dB/10)\n",
    "            res_mlp.append(compute_rate(FBB, FRF, WBB, WRF, H, SNR))\n",
    "    return res_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a57c3ff-ba08-4bb5-a310-931424e97898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF loss: tensor(1.8258)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.748510360717773,\n",
       " 8.554444313049316,\n",
       " 11.645604133605957,\n",
       " 14.876102447509766,\n",
       " 18.164989471435547,\n",
       " 21.475706100463867]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = scipy.io.loadmat('hb_test_144_36.mat')\n",
    "H = torch.tensor(test_data['H'].transpose(2,0,1), dtype = torch.cfloat)\n",
    "rate_test(test_loader, H)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe02ee55-9cc3-496b-81c9-85e3bae686e8",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] X. Yu, J.-C. Shen, J. Zhang, and K. B. Letaief, “Alternating minimization algorithms for hybrid precoding in millimeter wave mimo systems,” IEEE J. Sel. Topics Signal Process., vol. 10, no. 3, pp. 485–500, 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae41a4f5-57d3-4c9d-bac2-d0564eca4696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
