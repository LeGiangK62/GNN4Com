{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7458f182-c932-4c6b-bf25-97de2f0f655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import scipy.io\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU, ELU, Sigmoid, BatchNorm1d as BN, ReLU6 as ReLU6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fe4e72-90d8-47da-8206-a85f001a76fb",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cb580a-7571-40f2-9fb6-a571c4593114",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "To compute the spectral efficiency, both transmitter and receiver should be optimized with NN. So the dataset contains F_opt and W_opt.\n",
    "\n",
    "For unrolling-based methods, the input does not need normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c30f889-e07f-4535-a01f-96589baaedb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_layouts = 10000\n",
    "test_layouts = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301b51bd-f5dc-4601-9006-e85398ae8807",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('hb_train_144_36.mat')\n",
    "Fopt_train = data['Fopt'].transpose(2,0,1)\n",
    "Wopt_train = data['Wopt'].transpose(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28e57470-defc-443e-9b4a-8eda43c4f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = scipy.io.loadmat('hb_test_144_36.mat')\n",
    "Fopt_test = test_data['Fopt'].transpose(2,0,1)\n",
    "Wopt_test = test_data['Wopt'].transpose(2,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aad763-e338-4eb9-b001-c82dcddce48b",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78c8da38-6023-444f-a0a6-7bf16c866a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, F_opt, W_opt):\n",
    "        'Initialization' \n",
    "        self.F_opt = torch.tensor(F_opt, dtype = torch.cfloat)\n",
    "        self.W_opt = torch.tensor(W_opt, dtype = torch.cfloat)\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.F_opt)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        F_opt = self.F_opt[index]\n",
    "        W_opt = self.W_opt[index]\n",
    "        return F_opt, W_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "896b4cc6-c83f-440f-aac0-34b5709897e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = PCDataset(Fopt_train, Wopt_train)\n",
    "test_data = PCDataset(Fopt_test, Wopt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c15a1b5-8261-40f7-a249-efe12663684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, test_layouts, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595ac7b3-62ce-4a0e-9734-ab639a1ac892",
   "metadata": {},
   "source": [
    "#### Loss function\n",
    "As the phase shifter matrix is block diagonal, we first define a block diagonal mask## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939303a1-c74d-4e4e-821d-81b9c46ba8b2",
   "metadata": {},
   "source": [
    "#### Loss function\n",
    "As the phase shifter matrix is block diagonal, we first define a block diagonal mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65f848ad-1048-4337-b36c-ebe6ca4c083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_r, N_t, N_RF, N_s = Wopt_train.shape[1], Fopt_train.shape[1], 18, Fopt_train.shape[2]\n",
    "Fmask = np.zeros((1,N_t, N_RF) )\n",
    "Wmask = np.zeros((1,N_r, N_RF) )\n",
    "for i in range(N_RF):\n",
    "    Fmask[0,i*N_t//N_RF: (i+1)*N_t//N_RF,i] = np.ones((N_t//N_RF) )\n",
    "    Wmask[0,i*N_r//N_RF: (i+1)*N_r//N_RF,i] = np.ones((N_r//N_RF) )\n",
    "Fmask = torch.tensor(Fmask, dtype = torch.cfloat)\n",
    "Wmask = torch.tensor(Wmask, dtype = torch.cfloat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967c3f76-8679-4402-8892-8b537092c819",
   "metadata": {},
   "source": [
    "The neural network module only needs to output F_BB and W_BB. F_RF and W_RF can be obtained by using (33) in [1].\n",
    "\n",
    "Note: New version pytorch supports complex valued auto differentiation. Please refer to https://pytorch.org/docs/stable/complex_numbers.html for details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd99b135-3f2b-4b09-b02e-2a0e0f280fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FMF_loss(F_BB, F_opt):\n",
    "    F_BB = F_BB/torch.norm(F_BB, p = 'fro', dim = [1,2], keepdim = True) * math.sqrt(N_RF * N_s)\n",
    "    F_RF = F_opt @ F_BB.conj().transpose(1,2)\n",
    "    F_RF = F_RF/torch.abs(F_RF)\n",
    "    F_RF = Fmask * F_RF / math.sqrt(N_t)\n",
    "    return torch.mean(torch.norm(F_opt - F_RF @ F_BB, dim = [1,2])**2)\n",
    "def WMF_loss(W_BB, W_opt):\n",
    "    W_BB = W_BB/torch.norm(W_BB, p = 'fro', dim = [1,2], keepdim = True) * math.sqrt(N_RF * N_s)\n",
    "    W_RF = W_opt @ W_BB.conj().transpose(1,2)\n",
    "    W_RF = W_RF/torch.abs(W_RF)\n",
    "    W_RF = Wmask * W_RF / math.sqrt(N_r)\n",
    "    return torch.mean(torch.norm(W_opt - W_RF @ W_BB, dim = [1,2])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75fd9799-e1d9-4ed0-98a8-55550c1ef6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AltMin_Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AltMin_Net, self).__init__()\n",
    "        self.out_dim = N_RF\n",
    "        self.lin = Lin(2*N_RF, 2*N_RF)\n",
    "        \n",
    "    def complex_lin(self, inp):\n",
    "        lin_inp = torch.cat((inp.real, inp.imag), axis = -1)\n",
    "        out = self.lin(lin_inp)\n",
    "        out_real = torch.unsqueeze(out[:, :, :self.out_dim], axis = -1)\n",
    "        out_imag = torch.unsqueeze(out[:, :, self.out_dim:self.out_dim*2], axis = -1)\n",
    "        out = torch.cat((out_real, out_imag), axis = -1)\n",
    "        return torch.view_as_complex(out)\n",
    "        \n",
    "    def forward(self, F_opt, W_opt):\n",
    "        bs = F_opt.shape[0]\n",
    "        F_RF = Fmask * torch.randn(bs, N_t, N_RF)\n",
    "        for i in range(10):\n",
    "            F_BB = F_RF.transpose(1,2) @ F_opt\n",
    "            F_BB = F_BB/torch.norm(F_BB, p = 'fro', dim = [1,2], keepdim = True) * math.sqrt(N_RF * N_s)\n",
    "            F_RF = F_opt @ F_BB.conj().transpose(1,2)\n",
    "            F_RF = F_RF/torch.abs(F_RF)\n",
    "            F_RF = Fmask * F_RF / math.sqrt(N_t)\n",
    "            F_RF = self.complex_lin(F_RF)\n",
    "            \n",
    "        W_RF = Wmask * torch.randn(bs, N_r, N_RF)\n",
    "        for i in range(10):\n",
    "            W_BB = W_RF.transpose(1,2) @ W_opt\n",
    "            W_BB = W_BB/torch.norm(W_BB, p = 'fro', dim = [1,2], keepdim = True) * math.sqrt(N_RF * N_s)\n",
    "            W_RF = W_opt @ W_BB.conj().transpose(1,2)\n",
    "            W_RF = W_RF/torch.abs(W_RF)\n",
    "            W_RF = Wmask * W_RF / math.sqrt(N_r)\n",
    "            W_RF = self.complex_lin(W_RF)\n",
    "        \n",
    "        return F_BB, W_BB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86932d4d-0010-4a89-bf95-d716b88f4296",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "963706f1-de1c-4280-ab0c-634cba00cad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    \"\"\" Train for one epoch. \"\"\"\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    for batch_idx, (F_opt_train, W_opt_train) in enumerate(train_loader):\n",
    "        #data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        Foutput, Woutput = model(F_opt_train, W_opt_train)\n",
    "        loss = FMF_loss(Foutput, F_opt_train) + WMF_loss(Woutput, W_opt_train)\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * len(F_opt_train)\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb5e11aa-d6e3-435d-af38-df4aeac79f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for (F_opt_test, W_opt_test) in loader:\n",
    "        #data = data.to(device)\n",
    "        Foutput, Woutput = model(F_opt_test, W_opt_test)\n",
    "        loss = FMF_loss(Foutput, F_opt_test) + WMF_loss(Woutput, W_opt_test)\n",
    "        correct += loss.item() * len(F_opt_test)\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5b3582b-df5d-4752-930b-06c2e4300219",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AltMin_Net()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21c1ddfd-d969-4b29-9216-7fccf9aa454e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000, Train Rate: 3.2265, Test Rate: 3.2230\n",
      "Epoch 010, Train Rate: 2.2132, Test Rate: 2.2205\n",
      "Epoch 020, Train Rate: 1.6425, Test Rate: 1.6502\n",
      "Epoch 030, Train Rate: 1.4366, Test Rate: 1.4467\n",
      "Epoch 040, Train Rate: 1.3396, Test Rate: 1.3520\n",
      "Epoch 050, Train Rate: 1.2877, Test Rate: 1.2989\n",
      "Epoch 060, Train Rate: 1.2590, Test Rate: 1.2695\n",
      "Epoch 070, Train Rate: 1.2375, Test Rate: 1.2488\n",
      "Epoch 080, Train Rate: 1.2085, Test Rate: 1.2196\n",
      "Epoch 090, Train Rate: 1.2028, Test Rate: 1.2141\n",
      "Epoch 100, Train Rate: 1.1825, Test Rate: 1.1931\n",
      "Epoch 110, Train Rate: 1.1817, Test Rate: 1.1929\n",
      "Epoch 120, Train Rate: 1.1645, Test Rate: 1.1761\n",
      "Epoch 130, Train Rate: 1.1550, Test Rate: 1.1662\n",
      "Epoch 140, Train Rate: 1.1474, Test Rate: 1.1585\n",
      "Epoch 150, Train Rate: 1.1485, Test Rate: 1.1594\n",
      "Epoch 160, Train Rate: 1.1420, Test Rate: 1.1533\n",
      "Epoch 170, Train Rate: 1.1399, Test Rate: 1.1510\n",
      "Epoch 180, Train Rate: 1.1368, Test Rate: 1.1478\n",
      "Epoch 190, Train Rate: 1.1369, Test Rate: 1.1477\n"
     ]
    }
   ],
   "source": [
    "record = []\n",
    "for epoch in range(200):\n",
    "    if(epoch % 10 == 0):\n",
    "        train_rate = test(train_loader)\n",
    "        test_rate = test(test_loader)\n",
    "        print('Epoch {:03d}, Train Rate: {:.4f}, Test Rate: {:.4f}'.format(\n",
    "            epoch, train_rate, test_rate))\n",
    "        record.append([train_rate, test_rate])\n",
    "    train(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afb176e-3975-4340-b3b3-a835589deaf1",
   "metadata": {},
   "source": [
    "## Compute spectral efficiency\n",
    "The rate computation function is from [1] https://github.com/yuxianghao/Alternating-minimization-algorithms-for-hybrid-precoding-in-millimeter-wave-MIMO-systems/blob/Initial/Narrowband/SDR-AltMin/main_SNR.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "023f74dd-8784-49da-a8fe-3c3f25c32b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FBB2FRF(F_BB, F_opt):\n",
    "    F_BB = F_BB/torch.norm(F_BB, p = 'fro', dim = [1,2], keepdim = True) * math.sqrt(N_RF * N_s)\n",
    "    F_RF = F_opt @ F_BB.conj().transpose(1,2)\n",
    "    F_RF = F_RF/torch.abs(F_RF)\n",
    "    F_RF = Fmask * F_RF / math.sqrt(N_t)\n",
    "    return F_BB, F_RF\n",
    "\n",
    "def WBB2WRF(W_BB, W_opt):\n",
    "    W_BB = W_BB/torch.norm(W_BB, p = 'fro', dim = [1,2], keepdim = True) * math.sqrt(N_RF * N_s)\n",
    "    W_RF = W_opt @ W_BB.conj().transpose(1,2)\n",
    "    W_RF = W_RF/torch.abs(W_RF)\n",
    "    W_RF = Wmask * W_RF / math.sqrt(N_r)\n",
    "    return W_BB, W_RF\n",
    "\n",
    "def compute_rate(FBB, FRF, WBB, WRF, H, SNR):\n",
    "    '''Matlab code: log2(det(eye(Ns) + SNR(s)/Ns * pinv(WRF * WBB) * H(:,:,reali) * FRF * FBB * FBB' * FRF' * H(:,:,reali)' * WRF * WBB))\n",
    "    '''\n",
    "    rate = torch.log2(torch.det(torch.eye(N_s) + SNR/N_s * torch.linalg.pinv(WRF @ WBB) @ H @ FRF @ FBB @ FBB.conj().transpose(1,2)\n",
    "                                         @ FRF.conj().transpose(1,2) @ H.conj().transpose(1,2) @ WRF @ WBB))\n",
    "    return float(torch.mean(rate).detach().numpy().real)\n",
    "\n",
    "def rate_test(loader, H):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for (F_opt,  W_opt) in loader:\n",
    "            FBB, WBB = model(F_opt, W_opt)\n",
    "            FBB, FRF = FBB2FRF(FBB, F_opt)\n",
    "            WBB, WRF = WBB2WRF(WBB, W_opt)\n",
    "            \n",
    "            print('MF loss:', WMF_loss(WBB, W_opt) + FMF_loss(FBB, F_opt))\n",
    "        \n",
    "        SNR_dBs = np.arange(-15, 15, 5)\n",
    "        res_mlp = []\n",
    "        res_opt = []\n",
    "        for SNR_dB in SNR_dBs:\n",
    "            SNR = 10**(SNR_dB/10)\n",
    "            res_mlp.append(compute_rate(FBB, FRF, WBB, WRF, H, SNR))\n",
    "    return res_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eb93af-1374-446c-8176-97d68186d8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = scipy.io.loadmat('hb_test_144_36.mat')\n",
    "H = torch.tensor(test_data['H'].transpose(2,0,1), dtype = torch.cfloat)\n",
    "final_test(test_loader, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9a272a-9b6d-4409-888a-bbc0a14ae4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
