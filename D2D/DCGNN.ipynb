{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a23849f-d6bc-4363-b193-352eaac83a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import helper_functions\n",
    "from FPLinQ import FP_optimize, FP\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from dgl.data import DGLDataset\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch.nn as nn\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU, Sigmoid, BatchNorm1d as BN, ReLU6 as ReLU6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49438e7c-1d92-49e7-86ce-3fbe5264ef2c",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4257ca-57eb-4c46-b517-a532307f4128",
   "metadata": {},
   "source": [
    "#### Define system parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86f38646-ffe1-454c-bcc0-54de3a4e387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_noise = 0.1\n",
    "c = 1/np.sqrt(2)\n",
    "train_K = 20\n",
    "test_K = 20\n",
    "train_layouts = 20000\n",
    "test_layouts = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d6c3c5-712e-4168-a6b1-36f63f19b967",
   "metadata": {},
   "source": [
    "#### Generate Channel\n",
    "We follow [1] to generate channel matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2705215-2159-46ae-93e2-31c130570219",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel_losses = np.abs(c * np.random.randn(train_layouts, train_K, train_K) + c * 1j * np.random.randn(train_layouts, train_K, train_K))\n",
    "test_channel_losses = np.abs(c * np.random.randn(test_layouts, test_K, test_K) + c * 1j * np.random.randn(test_layouts, test_K, test_K))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b05064-bd00-4656-8189-d9b3611c293f",
   "metadata": {},
   "source": [
    "#### Compute the label for training and test dataset via FPLinQ\n",
    "The code for FPlinQ is copied from [2] https://github.com/willtop/Spatial_Deep_Learning_for_Wireless_Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72424c2c-6621-4bda-b829-f62162931e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training dataset, we do not generate labels\n",
    "## Get direct channel CSI, i.e., diag part of channel matrix\n",
    "direct_train = helper_functions.get_directLink_channel_losses(train_channel_losses)\n",
    "## Get interference channel CSI, i.e., off-diag part of channel matrix\n",
    "cross_train = helper_functions.get_crossLink_channel_losses(train_channel_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ecfbb9a-f1f3-48ba-b099-926681ddac1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum rate by FPlinQ: 4.280697775775529\n",
      "Sum rate by Best FPlinQ: 4.634149557657047\n"
     ]
    }
   ],
   "source": [
    "## To provide a test baseline, we run FPlinQ with 100 different initializations, and take the highest sum rate\n",
    "direct_test = helper_functions.get_directLink_channel_losses(test_channel_losses)\n",
    "cross_test = helper_functions.get_crossLink_channel_losses(test_channel_losses)\n",
    "\n",
    "rates_all = []\n",
    "for i in range(100):\n",
    "    init_x = np.random.rand(test_layouts, test_K,1)\n",
    "    Y = FP(np.ones([test_layouts, test_K]), test_channel_losses, var_noise, init_x)\n",
    "    rates = np.expand_dims(helper_functions.compute_rates(var_noise, \n",
    "                Y, direct_test, cross_test), axis = 0)\n",
    "    rates_all.append(rates)\n",
    "    \n",
    "rates_all = np.concatenate(rates_all)\n",
    "sr = np.mean(np.sum(rates[0,:,:],axis=1))\n",
    "sr_max = np.mean(np.max(np.sum(rates_all, axis = -1), axis = 0))\n",
    "y_test = Y\n",
    "print('Sum rate by FPlinQ:', sr)\n",
    "print('Sum rate by Best FPlinQ:', sr_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72b6ab7-c980-40c1-a271-a762554fede3",
   "metadata": {},
   "source": [
    "#### Create DGL Dataset\n",
    "Please refer to https://docs.dgl.ai/guide/data.html for a tutorial for the usage of DGL dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e2530f0-9198-4040-8d53-ed7e1b7e3ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCDataset(DGLDataset):\n",
    "    def __init__(self, csi, direct, cross):\n",
    "        self.data = csi\n",
    "        \n",
    "        self.direct = torch.tensor(direct, dtype = torch.float)\n",
    "        self.cross = torch.tensor(cross, dtype = torch.float)\n",
    "        self.get_cg()\n",
    "        super().__init__(name='power_control')\n",
    "    \n",
    "    def build_graph(self, idx):\n",
    "        H = self.data[idx,:,:]\n",
    "        \n",
    "        graph = dgl.graph(self.adj, num_nodes=train_K)\n",
    "        \n",
    "        node_features = torch.tensor(np.expand_dims(np.diag(H),axis=1), dtype = torch.float)\n",
    "        node_features = torch.cat([node_features, torch.ones_like(node_features)], axis = 1)\n",
    "        ## Node feature of the k-th node is the direct link channel of k-th pair\n",
    "        \n",
    "        edge_features  = []\n",
    "        for e in self.adj:\n",
    "            edge_features.append([H[e[0],e[1]],H[e[1],e[0]],1])\n",
    "        ## Edge feature between node e[0] and e[1] is the interference channel between e[0]-th pair and e[1]-th pair\n",
    "        \n",
    "        graph.ndata['feat'] = node_features\n",
    "        graph.edata['feat'] = torch.tensor(edge_features, dtype = torch.float)\n",
    "        return graph\n",
    "    \n",
    "    def get_cg(self):\n",
    "        ## The graph is a complete graph\n",
    "        self.adj = []\n",
    "        for i in range(0,train_K):\n",
    "            for j in range(0,train_K):\n",
    "                if(not(i==j)):\n",
    "                    self.adj.append([i,j])\n",
    "            \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        return self.graph_list[index], self.direct[index], self.cross[index]\n",
    "\n",
    "    def process(self):\n",
    "        n = len(self.data)\n",
    "        self.graph_list = []\n",
    "        for i in range(n):\n",
    "            graph = self.build_graph(i)\n",
    "            self.graph_list.append(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eaf4a38-5a84-4f6a-b9a7-c7d498157785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please refer to https://docs.dgl.ai/en/0.2.x/tutorials/basics/4_batch.html for details of collate\n",
    "def collate(samples):\n",
    "    # The input `samples` is a list of pairs\n",
    "    #  (graph, label).\n",
    "    graphs, direct, cross = map(list, zip(*samples))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    return batched_graph, torch.stack(direct), torch.stack(cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9b1b139-f54e-41c8-860d-c89d0341685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = PCDataset(train_channel_losses, direct_train, cross_train)\n",
    "test_data = PCDataset(test_channel_losses, direct_test, cross_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "777c1ffc-c73a-4b3c-8d1d-7cfd500b0876",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size, shuffle=True, collate_fn=collate)\n",
    "test_loader = DataLoader(test_data, test_layouts, shuffle=False, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f804e89-36df-4728-8289-a28bdb52f797",
   "metadata": {},
   "source": [
    "## Build Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66abd93a-6eae-44bf-b565-355b86b5c2f1",
   "metadata": {},
   "source": [
    "#### Define loss function\n",
    "Rewrite compute_rates in helper_functions.py via Pytorch functions and take an negative sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e81df454-dcc6-4bc9-a033-770622dd835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_loss(allocs, directlink_channel_losses, crosslink_channel_losses):\n",
    "    SINRs_numerators = allocs * directlink_channel_losses\n",
    "    SINRs_denominators = torch.squeeze(torch.matmul(crosslink_channel_losses, torch.unsqueeze(allocs, axis=-1))) + var_noise\n",
    "    SINRs = SINRs_numerators / SINRs_denominators\n",
    "    rates = torch.log2(1 + SINRs)\n",
    "    return -torch.mean(torch.sum(rates, axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f511fe-4bcd-4b17-bf0d-04fc792662ad",
   "metadata": {},
   "source": [
    "#### Message Passing Modules \n",
    "Please refer to https://docs.dgl.ai/guide/message-api.html for the usage of DGL message-passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31118814-0661-429c-9539-98921362d64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(channels, batch_norm=True):\n",
    "    return Seq(*[\n",
    "        Seq(Lin(channels[i - 1], channels[i]), ReLU(), BN(channels[i]))\n",
    "        for i in range(1, len(channels))\n",
    "    ])\n",
    "class EdgeConv(nn.Module):\n",
    "    def __init__(self, mlp, **kwargs):\n",
    "        super(EdgeConv, self).__init__()\n",
    "        self.mlp = mlp\n",
    "        #self.reset_parameters()\n",
    "\n",
    "    def concat_message_function(self, edges):\n",
    "        return {'out': torch.cat([edges.src['hid'], edges.dst['hid'], edges.data['feat']], axis=1)}\n",
    "    \n",
    "    def forward(self, g):\n",
    "        g.apply_edges(self.concat_message_function)\n",
    "        g.edata['out'] = self.mlp(g.edata['out'])\n",
    "        g.update_all(fn.copy_edge('out', 'm'),\n",
    "                     fn.mean('m', 'hid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4791f7f-0803-4be2-85bf-fddeafbad1f1",
   "metadata": {},
   "source": [
    "#### GNN Modules \n",
    "Please refer to https://docs.dgl.ai/guide/nn-construction.html#guide-nn-construction for usage of DGL GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76467d36-1110-4966-abfe-412bc0e518c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = EdgeConv(MLP([7, 16]))\n",
    "        self.conv2 = EdgeConv(MLP([2*16+3, 32]))\n",
    "        self.mlp = MLP([32, 16])\n",
    "        self.mlp = Seq(*[self.mlp, Seq(Lin(16, 1), Sigmoid())])\n",
    "\n",
    "    def forward(self, g):\n",
    "        g.ndata['hid'] = g.ndata['feat']\n",
    "        self.conv1(g)\n",
    "        self.conv2(g)\n",
    "        out = self.mlp(g.ndata['hid'])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7a6f38f-8102-4c5e-90e2-6e58e65e1794",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc11ef38-5cf7-492d-9691-b69ad3d9fdef",
   "metadata": {},
   "source": [
    "## Training and Test\n",
    "The training is similar to the node regression task, please refer to https://docs.dgl.ai/en/0.6.x/guide/training-node.html for DGL node regression training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc0addd5-16ed-4cda-8dd4-5406e00205bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    \"\"\" Train for one epoch. \"\"\"\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    for batch_idx, (g, d_train, c_train) in enumerate(train_loader):\n",
    "        #data = data.to(device)\n",
    "        n = len(g.ndata['feat'])\n",
    "        bs = len(g.ndata['feat'])//train_K\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(g).reshape(bs,-1)\n",
    "        loss = rate_loss(output, d_train, c_train)\n",
    "        loss.backward()\n",
    "        \n",
    "        loss_all += loss.item() * bs\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05e3317b-02a4-4476-aea4-212122f4244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for (g, d_test, c_test) in loader:\n",
    "        n = len(g.ndata['feat'])\n",
    "        bs = len(g.ndata['feat'])//train_K\n",
    "        #data = data.to(device)\n",
    "        output = model(g).reshape(bs,-1)\n",
    "        loss = rate_loss(output, d_test, c_test)\n",
    "        correct += loss.item() * bs\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a319dc6-65aa-49de-b766-276dc47ba9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000, Train Rate: -1.4705, Test Rate: -1.4736\n",
      "Epoch 005, Train Rate: -4.3329, Test Rate: -4.2711\n",
      "Epoch 010, Train Rate: -4.4226, Test Rate: -4.3682\n",
      "Epoch 015, Train Rate: -4.4590, Test Rate: -4.4254\n",
      "Epoch 020, Train Rate: -4.4616, Test Rate: -4.4187\n",
      "Epoch 025, Train Rate: -4.4980, Test Rate: -4.4837\n",
      "Epoch 030, Train Rate: -4.4881, Test Rate: -4.4580\n",
      "Epoch 035, Train Rate: -4.4885, Test Rate: -4.4547\n",
      "Epoch 040, Train Rate: -4.4120, Test Rate: -4.3869\n",
      "Epoch 045, Train Rate: -4.4727, Test Rate: -4.3986\n"
     ]
    }
   ],
   "source": [
    "record = []\n",
    "for epoch in range(0, 50):\n",
    "    if(epoch % 5 == 0):\n",
    "        with torch.no_grad():\n",
    "            train_rate = test(train_loader)\n",
    "            test_rate = test(test_loader)\n",
    "        print('Epoch {:03d}, Train Rate: {:.4f}, Test Rate: {:.4f}'.format(\n",
    "            epoch, train_rate, test_rate))\n",
    "        record.append([train_rate, test_rate])\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb83ab61-c980-4359-9c1c-a81f81c0391d",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] H. Sun, X. Chen, Q. Shi, M. Hong, X. Fu, and N. D. Sidiropoulos, “Learning to optimize: Training deep neural networks for interference management,” IEEE Trans. Signal Process., vol. 66, pp. 5438 – 5453, Oct. 2018.\n",
    "[2]  W. Cui, K. Shen, and W. Yu, “Spatial deep learning for wireless scheduling,” IEEE J. Sel. Areas Commun., vol. 37, Jun. 2019."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
